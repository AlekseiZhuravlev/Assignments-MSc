{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exam: MA-INF4316 Graph Representation Learning\n",
    "\n",
    "- Wintersemester 2021/2022\n",
    "- Exam: 1\n",
    "- Date 2022-02-21\n",
    "- Examiner: Dr. Pascal Welke\n",
    "\n",
    "### To be filled by the student\n",
    "- Name: Aleksei\n",
    "- Given Name: Zhuravlev\n",
    "- Matriculation number:\n",
    "- Course of Studies: MSc Computer Science\n",
    "\n",
    "(Please enter your data here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vertices 34118\n",
      "edges 429113\n"
     ]
    }
   ],
   "source": [
    "import igraph\n",
    "\n",
    "g = igraph.Graph.Read_Pickle('twitch.pickle')\n",
    "\n",
    "print('vertices', len(g.vs))\n",
    "print('edges', len(g.es))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean degree 25.154639779588486\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "print('mean degree', np.mean(g.degree(g.vs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_sane_density(vertex, graph):\n",
    "    neighbors = graph.neighbors(vertex)\n",
    "    degree = len(neighbors)\n",
    "    \n",
    "    if degree <= 1:\n",
    "        return 0\n",
    "    else:   \n",
    "        subgraph = graph.induced_subgraph(neighbors)\n",
    "        density = 2 * len(subgraph.es) / (degree * (degree - 1))\n",
    "        return density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42 0.12323232323232323\n",
      "123 0.11956521739130435\n",
      "11024 0\n",
      "11585 0.06159420289855073\n",
      "12280 0\n",
      "34117 0.20512820512820512\n"
     ]
    }
   ],
   "source": [
    "vertex_ids = [42, 123, 11024, 11585, 12280, 34117]\n",
    "\n",
    "for vertex in vertex_ids:\n",
    "    print(vertex, compute_sane_density(vertex, g))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "degeneracies = g.coreness()\n",
    "pageranks = g.pagerank()\n",
    "degrees = g.degree(g.vs)\n",
    "\n",
    "sane_densities = [compute_sane_density(vertex, g) for vertex in g.vs]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([4.50000000e+01, 4.04561421e-05, 3.00000000e+01, 1.23232323e-01]),\n",
       " array([2.40000000e+01, 2.96387338e-05, 1.50000000e+01, 1.19565217e-01]),\n",
       " array([1.00000000e+00, 7.06692425e-06, 1.00000000e+00, 0.00000000e+00]),\n",
       " array([2.40000000e+01, 6.10208326e-05, 1.10000000e+01, 6.15942029e-02]),\n",
       " array([1.00000000e+00, 6.69281948e-06, 1.00000000e+00, 0.00000000e+00]),\n",
       " array([1.30000000e+01, 2.18730179e-05, 1.20000000e+01, 2.05128205e-01])]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_vectors = np.array(list(zip(degrees, pageranks, degeneracies, sane_densities)))\n",
    "g.vs['features'] = feature_vectors\n",
    "g.vs[vertex_ids]['features']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train, vertices: 27558, edges: 338432\n",
      "validation, vertices: 4648, edges: 59382\n",
      "test, vertices: 1912, edges: 31299\n"
     ]
    }
   ],
   "source": [
    "train_g = g.induced_subgraph(g.vs.select(lang_in=['DE','ENGB', 'FR','RU']))\n",
    "val_g = g.induced_subgraph(g.vs.select(lang_eq='ES'))\n",
    "test_g = g.induced_subgraph(g.vs.select(lang_eq='PTBR'))\n",
    "\n",
    "print(f'train, vertices: {len(train_g.vs)}, edges: {len(train_g.es)}')\n",
    "print(f'validation, vertices: {len(val_g.vs)}, edges: {len(val_g.es)}')\n",
    "print(f'test, vertices: {len(test_g.vs)}, edges: {len(test_g.es)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kernel': 'linear', 'C': 0.001, 'accuracy': 0.6693201376936316}\n",
      "{'kernel': 'linear', 'C': 0.01, 'accuracy': 0.6701807228915663}\n",
      "{'kernel': 'linear', 'C': 0.1, 'accuracy': 0.6699655765920827}\n",
      "{'kernel': 'rbf', 'C': 0.001, 'accuracy': 0.7074010327022375}\n",
      "{'kernel': 'rbf', 'C': 0.01, 'accuracy': 0.6805077452667814}\n",
      "{'kernel': 'rbf', 'C': 0.1, 'accuracy': 0.6688898450946644}\n",
      "[{'kernel': 'rbf', 'C': 0.001, 'accuracy': 0.7074010327022375}, {'kernel': 'rbf', 'C': 0.01, 'accuracy': 0.6805077452667814}, {'kernel': 'linear', 'C': 0.01, 'accuracy': 0.6701807228915663}, {'kernel': 'linear', 'C': 0.1, 'accuracy': 0.6699655765920827}, {'kernel': 'linear', 'C': 0.001, 'accuracy': 0.6693201376936316}, {'kernel': 'rbf', 'C': 0.1, 'accuracy': 0.6688898450946644}]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "parameters = {'kernel':('linear', 'rbf'), 'C':[0.001, 0.01, 0.1]}\n",
    "\n",
    "scores = []\n",
    "\n",
    "for kernel in ['linear', 'rbf']:\n",
    "    for C in [0.001, 0.01, 0.1]:\n",
    "        svc = svm.SVC(kernel=kernel, C=C)\n",
    "        svc.fit(train_g.vs['features'], train_g.vs['label'])\n",
    "        y_pred = svc.predict(val_g.vs['features'])\n",
    "        score = accuracy_score(val_g.vs['label'], y_pred)\n",
    "        scores.append({\n",
    "            'kernel': kernel,\n",
    "            'C': C,\n",
    "            'accuracy': score\n",
    "        })\n",
    "        \n",
    "        print({\n",
    "            'kernel': kernel,\n",
    "            'C': C,\n",
    "            'accuracy': score\n",
    "        })\n",
    "        \n",
    "print(\n",
    "    sorted(scores, key=lambda x: x['accuracy'], reverse=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(-1, -1), (-1, -1), (1, -1), (1, -1), (-1, -1), (-1, -1), (1, 1), (-1, -1), (-1, 1), (-1, 1)]\n",
      "0.6427824267782427\n"
     ]
    }
   ],
   "source": [
    "svc_best = svm.SVC(kernel='rbf', C=0.001)\n",
    "X_train = np.concatenate([train_g.vs['features'], val_g.vs['features']])\n",
    "y_train = np.concatenate([train_g.vs['label'], val_g.vs['label']])\n",
    "\n",
    "svc.fit(X_train, y_train)\n",
    "y_pred = svc.predict(test_g.vs['features'])\n",
    "score = accuracy_score(test_g.vs['label'], y_pred)\n",
    "\n",
    "print(list(zip(y_pred[0:10], test_g.vs['label'][0:10])))\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   -1 17725]\n",
      " [    1 14481]]\n"
     ]
    }
   ],
   "source": [
    "# look at what class dominates\n",
    "classes, counts = np.unique(y_train, return_counts = True)\n",
    "print(np.array([classes, counts]).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of a majority vote classifier:  0.5503632863441594\n"
     ]
    }
   ],
   "source": [
    "print('accuracy of a majority vote classifier: ', counts[0] / sum(counts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is your result from Task 1.6 satisfactory?\n",
    "\n",
    "- By using vertex features we got a 10% increase in accuracy, so it was at least worth the effort. But 65% accuracy is still quite low and we should work on improving our model, e.g. by adding more features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def update(v, upd, agg, rk, r_0): \n",
    "    neighbors = v.neighbors() #return List of igraph vertices\n",
    "    multiset = [rk[neighbor.index] for neighbor in neighbors]\n",
    "    aggregation = agg(multiset)\n",
    "    return upd(rk[v.index], aggregation, r_0)\n",
    "\n",
    "def mpf(g, r0, k, upd, agg):\n",
    "    #Contains for each h and aLL vertices aLL LabeLs r_h(v), i.e messages[0][0] = r_0(u_0)\n",
    "    messages = []\n",
    "    #do the first iteration with r0\n",
    "    messages.append([r0(v) for v in g.vs])\n",
    "    for i in range(1, k+1):\n",
    "        messages.append(np.array([update(v, upd, agg, messages[-1], r0(v)) for v in g.vs]))\n",
    "    return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agg_func(multiset):\n",
    "    return sum(multiset)\n",
    "\n",
    "def upd_func(previous, aggregation, r_0):\n",
    "    return r_0 + aggregation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All vertices v should have the same color at the beginning, so we initialize r_0 to a set of 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1]\n",
      "[46 25  2 25  2 14]\n",
      "[1210751  182653     469   33511    3429  145136]\n"
     ]
    }
   ],
   "source": [
    "def r_0(v):\n",
    "    return 1\n",
    "\n",
    "messages = np.array(mpf(g, r_0, 3, upd_func, agg_func))\n",
    "\n",
    "vertex_ids = [42, 123, 11024, 11585, 12280, 34117]\n",
    "for i in [0, 1, 3]:\n",
    "    print(messages[i, vertex_ids])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "Could not find module 'C:\\ProgramData\\Anaconda3\\Lib\\site-packages\\torch_sparse\\_convert_cuda.pyd' (or one of its dependencies). Try using the full path with constructor syntax.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [50]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mF\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential, Linear, ReLU\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch_geometric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TUDataset\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch_geometric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataLoader\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch_geometric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GINConv, global_max_pool\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch_geometric\\__init__.py:4\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ModuleType\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mimportlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m import_module\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch_geometric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch_geometric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mloader\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch_geometric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch_geometric\\data\\__init__.py:1\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Data\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhetero_data\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HeteroData\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtemporal\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TemporalData\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch_geometric\\data\\data.py:20\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Tensor\n\u001b[1;32m---> 20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch_sparse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SparseTensor\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch_geometric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_store\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     23\u001b[0m     FeatureStore,\n\u001b[0;32m     24\u001b[0m     FeatureTensorType,\n\u001b[0;32m     25\u001b[0m     TensorAttr,\n\u001b[0;32m     26\u001b[0m     _field_status,\n\u001b[0;32m     27\u001b[0m )\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch_geometric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgraph_store\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     29\u001b[0m     EDGE_LAYOUT_TO_ATTR_NAME,\n\u001b[0;32m     30\u001b[0m     EdgeAttr,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     34\u001b[0m     edge_tensor_type_to_adj_type,\n\u001b[0;32m     35\u001b[0m )\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch_sparse\\__init__.py:19\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m spec \u001b[38;5;241m=\u001b[39m cuda_spec \u001b[38;5;129;01mor\u001b[39;00m cpu_spec\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spec \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 19\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_library\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43morigin\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not find module \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlibrary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_cpu\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m in \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     22\u001b[0m                       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mosp\u001b[38;5;241m.\u001b[39mdirname(\u001b[38;5;18m__file__\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\_ops.py:255\u001b[0m, in \u001b[0;36m_Ops.load_library\u001b[1;34m(self, path)\u001b[0m\n\u001b[0;32m    250\u001b[0m path \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_utils_internal\u001b[38;5;241m.\u001b[39mresolve_library_path(path)\n\u001b[0;32m    251\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m dl_open_guard():\n\u001b[0;32m    252\u001b[0m     \u001b[38;5;66;03m# Import the shared library into the process, thus running its\u001b[39;00m\n\u001b[0;32m    253\u001b[0m     \u001b[38;5;66;03m# static (global) initialization code in order to register custom\u001b[39;00m\n\u001b[0;32m    254\u001b[0m     \u001b[38;5;66;03m# operators with the JIT.\u001b[39;00m\n\u001b[1;32m--> 255\u001b[0m     \u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCDLL\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloaded_libraries\u001b[38;5;241m.\u001b[39madd(path)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\ctypes\\__init__.py:382\u001b[0m, in \u001b[0;36mCDLL.__init__\u001b[1;34m(self, name, mode, handle, use_errno, use_last_error, winmode)\u001b[0m\n\u001b[0;32m    379\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_FuncPtr \u001b[38;5;241m=\u001b[39m _FuncPtr\n\u001b[0;32m    381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m handle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 382\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle \u001b[38;5;241m=\u001b[39m \u001b[43m_dlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    383\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    384\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle \u001b[38;5;241m=\u001b[39m handle\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: Could not find module 'C:\\ProgramData\\Anaconda3\\Lib\\site-packages\\torch_sparse\\_convert_cuda.pyd' (or one of its dependencies). Try using the full path with constructor syntax."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Sequential, Linear, ReLU\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_geometric.nn import GINConv, global_max_pool\n",
    "import numpy as np\n",
    "\n",
    "dataset = TUDataset(root='/tmp/DHFR',  name='DHFR')\n",
    "test_dataset = dataset[:len(dataset) // 10]\n",
    "train_dataset = dataset[len(dataset) // 10:]\n",
    "test_loader = DataLoader(test_dataset, batch_size=128)\n",
    "train_loader = DataLoader(train_dataset, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "\n",
    "    if epoch == 51:\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = 0.5 * param_group['lr']\n",
    "    \n",
    "    if epoch == 76:\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = 0.5 * param_group['lr']\n",
    "\n",
    "    loss_all = 0\n",
    "    for data in train_loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data.x, data.edge_index, data.batch)\n",
    "        loss = F.nll_loss(output, data.y)\n",
    "        loss.backward()\n",
    "        loss_all += loss.item() * data.num_graphs\n",
    "        optimizer.step()\n",
    "    return loss_all / len(train_dataset)\n",
    "\n",
    "\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "\n",
    "    correct = 0\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        output = model(data.x, data.edge_index, data.batch)\n",
    "        pred = output.max(dim=1)[1]\n",
    "        correct += pred.eq(data.y).sum().item()\n",
    "    return correct / len(loader.dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "verbose = False\n",
    "\n",
    "# obviously, the models in this list need to be defined\n",
    "for model in [Net2(), Net3(), Net4(), Net5()]:\n",
    "    model = model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    "\n",
    "    for epoch in range(1, 101):\n",
    "        train_loss = train(epoch)\n",
    "        if verbose:\n",
    "            train_acc = test(train_loader)\n",
    "            test_acc = test(test_loader)\n",
    "            print('Epoch: {:03d}, Train Loss: {:.7f}, '\n",
    "                'Train Acc: {:.7f}, Test Acc: {:.7f}'.format(epoch, train_loss,\n",
    "                                                        train_acc, test_acc))\n",
    "    \n",
    "    print(f'model = {model.__class__}')\n",
    "    train_acc = test(train_loader)\n",
    "    test_acc = test(test_loader)\n",
    "    print('Epoch: {:03d}, Train Loss: {:.7f}, '\n",
    "        'Train Acc: {:.7f}, Test Acc: {:.7f}'.format(epoch, train_loss,\n",
    "                                                train_acc, test_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
