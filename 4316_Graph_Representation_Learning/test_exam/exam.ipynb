{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1FaPIWjgKq6"
      },
      "source": [
        "# Exam: MA-INF4316 Graph Representation Learning\n",
        "\n",
        "- Wintersemester 2021/2022\n",
        "- Exam: 1\n",
        "- Date 2022-02-21\n",
        "- Examiner: Dr. Pascal Welke\n",
        "\n",
        "### To be filled by the student\n",
        "- Name: Aleksei\n",
        "- Given Name: Zhuravlev\n",
        "- Matriculation number:\n",
        "- Course of Studies: MSc Computer Science\n",
        "\n",
        "(Please enter your data here)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "STlZ_P3hgKq9"
      },
      "source": [
        "# Task 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xFiPmtlUgKq9"
      },
      "source": [
        "## Task 1.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ozY0Rbg5gKq-",
        "outputId": "2f6aedc9-b9f0-4c0c-e69b-24f9072ebf2a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "vertices 34118\n",
            "edges 429113\n"
          ]
        }
      ],
      "source": [
        "import igraph\n",
        "\n",
        "g = igraph.Graph.Read_Pickle('twitch.pickle')\n",
        "\n",
        "print('vertices', len(g.vs))\n",
        "print('edges', len(g.es))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gWc_OZJlgKrA",
        "outputId": "2708d516-10eb-409a-dc2d-e1f01e7d8585"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mean degree 25.154639779588486\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "print('mean degree', np.mean(g.degree(g.vs)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "suLyl_VRgKrA"
      },
      "source": [
        "## Task 1.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zjvus50jgKrB"
      },
      "outputs": [],
      "source": [
        "def compute_sane_density(vertex, graph):\n",
        "    neighbors = graph.neighbors(vertex)\n",
        "    degree = len(neighbors)\n",
        "    \n",
        "    if degree <= 1:\n",
        "        return 0\n",
        "    else:   \n",
        "        subgraph = graph.induced_subgraph(neighbors)\n",
        "        density = 2 * len(subgraph.es) / (degree * (degree - 1))\n",
        "        return density"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qCPHkZ4GgKrB",
        "outputId": "1a23f112-681c-4336-da19-f1b2f504e030"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "42 0.12323232323232323\n",
            "123 0.11956521739130435\n",
            "11024 0\n",
            "11585 0.06159420289855073\n",
            "12280 0\n",
            "34117 0.20512820512820512\n"
          ]
        }
      ],
      "source": [
        "vertex_ids = [42, 123, 11024, 11585, 12280, 34117]\n",
        "\n",
        "for vertex in vertex_ids:\n",
        "    print(vertex, compute_sane_density(vertex, g))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v1QdD5YBgKrB"
      },
      "source": [
        "## Task 1.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8kHnBDZHgKrC"
      },
      "outputs": [],
      "source": [
        "degeneracies = g.coreness()\n",
        "pageranks = g.pagerank()\n",
        "degrees = g.degree(g.vs)\n",
        "\n",
        "sane_densities = [compute_sane_density(vertex, g) for vertex in g.vs]    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dL2slmQngKrC",
        "outputId": "1cadb08c-cb83-4579-a88d-9cc8762fc9aa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[array([4.50000000e+01, 4.04561421e-05, 3.00000000e+01, 1.23232323e-01]),\n",
              " array([2.40000000e+01, 2.96387338e-05, 1.50000000e+01, 1.19565217e-01]),\n",
              " array([1.00000000e+00, 7.06692425e-06, 1.00000000e+00, 0.00000000e+00]),\n",
              " array([2.40000000e+01, 6.10208326e-05, 1.10000000e+01, 6.15942029e-02]),\n",
              " array([1.00000000e+00, 6.69281948e-06, 1.00000000e+00, 0.00000000e+00]),\n",
              " array([1.30000000e+01, 2.18730179e-05, 1.20000000e+01, 2.05128205e-01])]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "feature_vectors = np.array(list(zip(degrees, pageranks, degeneracies, sane_densities)))\n",
        "g.vs['features'] = feature_vectors\n",
        "g.vs[vertex_ids]['features']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8BcGqHSSgKrD"
      },
      "source": [
        "## Task 1.4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F8-wHHVRgKrD",
        "outputId": "fceff272-1b3b-4f77-d4d4-e0034a63a5c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train, vertices: 27558, edges: 338432\n",
            "validation, vertices: 4648, edges: 59382\n",
            "test, vertices: 1912, edges: 31299\n"
          ]
        }
      ],
      "source": [
        "train_g = g.induced_subgraph(g.vs.select(lang_in=['DE','ENGB', 'FR','RU']))\n",
        "val_g = g.induced_subgraph(g.vs.select(lang_eq='ES'))\n",
        "test_g = g.induced_subgraph(g.vs.select(lang_eq='PTBR'))\n",
        "\n",
        "print(f'train, vertices: {len(train_g.vs)}, edges: {len(train_g.es)}')\n",
        "print(f'validation, vertices: {len(val_g.vs)}, edges: {len(val_g.es)}')\n",
        "print(f'test, vertices: {len(test_g.vs)}, edges: {len(test_g.es)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PnWZ8YEFgKrD"
      },
      "source": [
        "## Task 1.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SIhkgNI8gKrD",
        "outputId": "13f2874b-75ef-4d18-a297-8448133a2560"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'kernel': 'linear', 'C': 0.001, 'accuracy': 0.6693201376936316}\n",
            "{'kernel': 'linear', 'C': 0.01, 'accuracy': 0.6701807228915663}\n",
            "{'kernel': 'linear', 'C': 0.1, 'accuracy': 0.6699655765920827}\n",
            "{'kernel': 'rbf', 'C': 0.001, 'accuracy': 0.7074010327022375}\n",
            "{'kernel': 'rbf', 'C': 0.01, 'accuracy': 0.6805077452667814}\n",
            "{'kernel': 'rbf', 'C': 0.1, 'accuracy': 0.6688898450946644}\n",
            "[{'kernel': 'rbf', 'C': 0.001, 'accuracy': 0.7074010327022375}, {'kernel': 'rbf', 'C': 0.01, 'accuracy': 0.6805077452667814}, {'kernel': 'linear', 'C': 0.01, 'accuracy': 0.6701807228915663}, {'kernel': 'linear', 'C': 0.1, 'accuracy': 0.6699655765920827}, {'kernel': 'linear', 'C': 0.001, 'accuracy': 0.6693201376936316}, {'kernel': 'rbf', 'C': 0.1, 'accuracy': 0.6688898450946644}]\n"
          ]
        }
      ],
      "source": [
        "from sklearn import svm, datasets\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "parameters = {'kernel':('linear', 'rbf'), 'C':[0.001, 0.01, 0.1]}\n",
        "\n",
        "scores = []\n",
        "\n",
        "for kernel in ['linear', 'rbf']:\n",
        "    for C in [0.001, 0.01, 0.1]:\n",
        "        svc = svm.SVC(kernel=kernel, C=C)\n",
        "        svc.fit(train_g.vs['features'], train_g.vs['label'])\n",
        "        y_pred = svc.predict(val_g.vs['features'])\n",
        "        score = accuracy_score(val_g.vs['label'], y_pred)\n",
        "        scores.append({\n",
        "            'kernel': kernel,\n",
        "            'C': C,\n",
        "            'accuracy': score\n",
        "        })\n",
        "        \n",
        "        print({\n",
        "            'kernel': kernel,\n",
        "            'C': C,\n",
        "            'accuracy': score\n",
        "        })\n",
        "        \n",
        "print(\n",
        "    sorted(scores, key=lambda x: x['accuracy'], reverse=True)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Qg1fyb-gKrE"
      },
      "source": [
        "## Task 1.6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QQRc2vklgKrE",
        "outputId": "f5f9122f-db42-424f-f839-be659058bc23"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[(-1, -1), (-1, -1), (1, -1), (1, -1), (-1, -1), (-1, -1), (1, 1), (-1, -1), (-1, 1), (-1, 1)]\n",
            "0.6427824267782427\n"
          ]
        }
      ],
      "source": [
        "svc_best = svm.SVC(kernel='rbf', C=0.001)\n",
        "X_train = np.concatenate([train_g.vs['features'], val_g.vs['features']])\n",
        "y_train = np.concatenate([train_g.vs['label'], val_g.vs['label']])\n",
        "\n",
        "svc.fit(X_train, y_train)\n",
        "y_pred = svc.predict(test_g.vs['features'])\n",
        "score = accuracy_score(test_g.vs['label'], y_pred)\n",
        "\n",
        "print(list(zip(y_pred[0:10], test_g.vs['label'][0:10])))\n",
        "print(score)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7gljknAgKrE"
      },
      "source": [
        "## Task 1.7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6OAJ7-JFgKrF",
        "outputId": "21b31813-6381-4a00-ca00-7b8a4ed9a31f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[   -1 17725]\n",
            " [    1 14481]]\n"
          ]
        }
      ],
      "source": [
        "# look at what class dominates\n",
        "classes, counts = np.unique(y_train, return_counts = True)\n",
        "print(np.array([classes, counts]).T)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SIf1-GB0gKrF",
        "outputId": "cb542909-c9ad-4fcc-8c37-2dbb2325a961"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "accuracy of a majority vote classifier:  0.5503632863441594\n"
          ]
        }
      ],
      "source": [
        "print('accuracy of a majority vote classifier: ', counts[0] / sum(counts))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yrc7pxnVgKrF"
      },
      "source": [
        "Is your result from Task 1.6 satisfactory?\n",
        "\n",
        "- By using vertex features we got a 10% increase in accuracy, so it was at least worth the effort. But 65% accuracy is still quite low and we should work on improving our model, e.g. by adding more features."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1Rt-2nqgKrF"
      },
      "source": [
        "# Task 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ketEuW9gKrG"
      },
      "source": [
        "## Task 2.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tAW4z24RgKrG"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def update(v, upd, agg, rk, r_0): \n",
        "    neighbors = v.neighbors() #return List of igraph vertices\n",
        "    multiset = [rk[neighbor.index] for neighbor in neighbors]\n",
        "    aggregation = agg(multiset)\n",
        "    return upd(rk[v.index], aggregation, r_0)\n",
        "\n",
        "def mpf(g, r0, k, upd, agg):\n",
        "    #Contains for each h and aLL vertices aLL LabeLs r_h(v), i.e messages[0][0] = r_0(u_0)\n",
        "    messages = []\n",
        "    #do the first iteration with r0\n",
        "    messages.append([r0(v) for v in g.vs])\n",
        "    for i in range(1, k+1):\n",
        "        messages.append(np.array([update(v, upd, agg, messages[-1], r0(v)) for v in g.vs]))\n",
        "    return messages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c1_ZI1N3gKrG"
      },
      "outputs": [],
      "source": [
        "def agg_func(multiset):\n",
        "    return sum(multiset)\n",
        "\n",
        "def upd_func(previous, aggregation, r_0):\n",
        "    return r_0 + aggregation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83h34lPXgKrG"
      },
      "source": [
        "## Task 2.2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jzGSryT9gKrG"
      },
      "source": [
        "All vertices v should have the same color at the beginning, so we initialize r_0 to a set of 1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YkCt9K7pgKrG"
      },
      "source": [
        "## Task 2.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ecy1vugPgKrG",
        "outputId": "74e5683d-1e54-4338-e6c1-c0496e19e63d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1 1 1 1 1 1]\n",
            "[46 25  2 25  2 14]\n",
            "[1210751  182653     469   33511    3429  145136]\n"
          ]
        }
      ],
      "source": [
        "def r_0(v):\n",
        "    return 1\n",
        "\n",
        "messages = np.array(mpf(g, r_0, 3, upd_func, agg_func))\n",
        "\n",
        "vertex_ids = [42, 123, 11024, 11585, 12280, 34117]\n",
        "for i in [0, 1, 3]:\n",
        "    print(messages[i, vertex_ids])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h80hNmccgKrH"
      },
      "source": [
        "## Task 2.4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gKoA1_O1gKrH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYmmn2jegKrH"
      },
      "source": [
        "# Task 3"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pyg-lib torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric -f https://data.pyg.org/whl/torch-1.13.0+cu117.html"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aAJbtdfFgUUo",
        "outputId": "d235892a-d9f7-4553-be14-d691ea82db2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://data.pyg.org/whl/torch-1.13.0+cu117.html\n",
            "Collecting pyg-lib\n",
            "  Downloading https://data.pyg.org/whl/torch-1.13.0%2Bcu117/pyg_lib-0.1.0%2Bpt113cu117-cp38-cp38-linux_x86_64.whl (1.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m38.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch-scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-1.13.0%2Bcu117/torch_scatter-2.1.0%2Bpt113cu117-cp38-cp38-linux_x86_64.whl (10.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m94.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch-sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-1.13.0%2Bcu117/torch_sparse-0.6.16%2Bpt113cu117-cp38-cp38-linux_x86_64.whl (4.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m61.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch-cluster\n",
            "  Downloading https://data.pyg.org/whl/torch-1.13.0%2Bcu117/torch_cluster-1.6.0%2Bpt113cu117-cp38-cp38-linux_x86_64.whl (3.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch-spline-conv\n",
            "  Downloading https://data.pyg.org/whl/torch-1.13.0%2Bcu117/torch_spline_conv-1.2.1%2Bpt113cu117-cp38-cp38-linux_x86_64.whl (877 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m877.7/877.7 KB\u001b[0m \u001b[31m34.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch-geometric in /usr/local/lib/python3.8/dist-packages (2.2.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from torch-sparse) (1.7.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (4.64.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (2.25.1)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (5.9.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (1.21.6)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (3.0.9)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (2.11.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (1.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from jinja2->torch-geometric) (2.0.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torch-geometric) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torch-geometric) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torch-geometric) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torch-geometric) (4.0.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->torch-geometric) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->torch-geometric) (1.2.0)\n",
            "Installing collected packages: torch-spline-conv, torch-scatter, pyg-lib, torch-sparse, torch-cluster\n",
            "Successfully installed pyg-lib-0.1.0+pt113cu117 torch-cluster-1.6.0+pt113cu117 torch-scatter-2.1.0+pt113cu117 torch-sparse-0.6.16+pt113cu117 torch-spline-conv-1.2.1+pt113cu117\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cILDURB-gKrH",
        "outputId": "291d76b4-3f77-41fc-e401-a3795ece972b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch_geometric/deprecation.py:12: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
            "  warnings.warn(out)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import Sequential, Linear, ReLU\n",
        "from torch_geometric.datasets import TUDataset\n",
        "from torch_geometric.data import DataLoader\n",
        "from torch_geometric.nn import GINConv, global_max_pool, MLP\n",
        "import numpy as np\n",
        "\n",
        "dataset = TUDataset(root='/tmp/DHFR',  name='DHFR')\n",
        "test_dataset = dataset[:len(dataset) // 10]\n",
        "train_dataset = dataset[len(dataset) // 10:]\n",
        "test_loader = DataLoader(test_dataset, batch_size=128)\n",
        "train_loader = DataLoader(train_dataset, batch_size=128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-sMY7CpCgKrH"
      },
      "outputs": [],
      "source": [
        "def train(epoch, model, optimizer):\n",
        "    model.train()\n",
        "\n",
        "    if epoch == 51:\n",
        "        for param_group in optimizer.param_groups:\n",
        "            param_group['lr'] = 0.5 * param_group['lr']\n",
        "    \n",
        "    if epoch == 76:\n",
        "        for param_group in optimizer.param_groups:\n",
        "            param_group['lr'] = 0.5 * param_group['lr']\n",
        "\n",
        "    loss_all = 0\n",
        "    for data in train_loader:\n",
        "        data = data.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data.x, data.edge_index, data.batch)\n",
        "        loss = F.nll_loss(output, data.y)\n",
        "        loss.backward()\n",
        "        loss_all += loss.item() * data.num_graphs\n",
        "        optimizer.step()\n",
        "    return loss_all / len(train_dataset)\n",
        "\n",
        "\n",
        "def test(loader, model):\n",
        "    model.eval()\n",
        "\n",
        "    correct = 0\n",
        "    for data in loader:\n",
        "        data = data.to(device)\n",
        "        output = model(data.x, data.edge_index, data.batch)\n",
        "        pred = output.max(dim=1)[1]\n",
        "        correct += pred.eq(data.y).sum().item()\n",
        "    return correct / len(loader.dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oKcrlzfUgKrI"
      },
      "source": [
        "## Task 3.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o0pla5qvgKrI"
      },
      "outputs": [],
      "source": [
        "class Net(torch.nn.Module):\n",
        "    def __init__(self, num_layers):\n",
        "        super().__init__()\n",
        "\n",
        "        self.convs = torch.nn.ModuleList()\n",
        "\n",
        "        input_channels = dataset.num_node_features\n",
        "        for k in range(num_layers):\n",
        "            output_channels = 2 ** (7 - k + 1)\n",
        "            mlp = MLP([input_channels, 32, output_channels])\n",
        "            self.convs.append(GINConv(nn=mlp, train_eps=False))\n",
        "            input_channels = output_channels\n",
        "\n",
        "        self.mlp = MLP([input_channels, 32, dataset.num_classes])\n",
        "\n",
        "    def forward(self, x, edge_index, batch):\n",
        "        for conv in self.convs:\n",
        "            x = conv(x, edge_index).relu()\n",
        "        x = global_max_pool(x, batch)\n",
        "        x = self.mlp(x)\n",
        "\n",
        "        return F.log_softmax(x, dim=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hBVJVCl4gKrI"
      },
      "source": [
        "## Task 3.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L9vMxxoagKrI",
        "outputId": "9b3186ca-bd3e-4030-f135-045c4dbdb233"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model = 2 layers\n",
            "Train Loss: 0.0292484, Train Acc: 0.9471366, Test Acc: 0.7466667\n",
            "model = 3 layers\n",
            "Train Loss: 0.0247370, Train Acc: 0.9603524, Test Acc: 0.7466667\n",
            "model = 4 layers\n",
            "Train Loss: 0.0833111, Train Acc: 0.9030837, Test Acc: 0.5866667\n",
            "model = 5 layers\n",
            "Train Loss: 0.1045515, Train Acc: 0.8928047, Test Acc: 0.4666667\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "verbose = False\n",
        "\n",
        "def train_GIN(n_layers):\n",
        "    model = Net(n_layers)\n",
        "    model = model.to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
        "\n",
        "    for epoch in range(1, 101):\n",
        "        train_loss = train(epoch, model, optimizer)\n",
        "    \n",
        "    train_acc = test(train_loader, model)\n",
        "    test_acc = test(test_loader, model)\n",
        "\n",
        "    return train_loss, train_acc, test_acc\n",
        "\n",
        "\n",
        "for n_layers in [2,3,4,5]:\n",
        "    train_loss, train_acc, test_acc = train_GIN(n_layers)\n",
        "    print(f'model = {n_layers} layers')\n",
        "    print('Train Loss: {:.7f}, '\n",
        "        'Train Acc: {:.7f}, Test Acc: {:.7f}'.format(train_loss,\n",
        "                                                train_acc, test_acc))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Analysis: \n",
        "We can see that the test accuracy is the highest for the network with 3 layers. For 2 layers, the NN overfits the train set a little bit, and for 4 and 5 layers both the train and test set accuracies fall.\n",
        "\n",
        "The best choice is the NN with 3 layers, because it has the best test set accuracy and reasonable train set accuracy"
      ],
      "metadata": {
        "id": "3-zD_OGDsGE7"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eBg1Aan8gKrJ"
      },
      "source": [
        "## Task 3.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yd5at59SgKrJ",
        "outputId": "54613d54-1919-4fc1-9635-c4d976108b8b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train accuracy\n",
            "mean 0.9280469897209985, std 0.02164791423151834\n",
            "Test accuracy\n",
            "mean 0.6377777777777778, std 0.06773222512945853\n",
            "\n"
          ]
        }
      ],
      "source": [
        "train_acc_list = []\n",
        "test_acc_list = []\n",
        "\n",
        "for _ in range(6):\n",
        "    train_loss, train_acc, test_acc = train_GIN(3)\n",
        "    train_acc_list.append(train_acc)\n",
        "    test_acc_list.append(test_acc)\n",
        "\n",
        "print(f\"\"\"\n",
        "Train accuracy\n",
        "mean {np.mean(train_acc_list)}, std {np.std(train_acc_list)}\n",
        "Test accuracy\n",
        "mean {np.mean(test_acc_list)}, std {np.std(test_acc_list)}\n",
        "\"\"\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b_lU4vkFgKrJ"
      },
      "source": [
        "## Task 3.4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HHmtcgomgKrJ"
      },
      "outputs": [],
      "source": [
        "class NetLarge(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.convs = torch.nn.ModuleList()\n",
        "\n",
        "        input_channels = dataset.num_node_features\n",
        "\n",
        "        mlp = MLP([input_channels, 32, 64])\n",
        "        self.convs.append(GINConv(nn=mlp, train_eps=False))\n",
        "        mlp = MLP([64, 32, 64])\n",
        "        self.convs.append(GINConv(nn=mlp, train_eps=False))\n",
        "\n",
        "        self.mlp = MLP([64, 32, dataset.num_classes])\n",
        "\n",
        "    def forward(self, x, edge_index, batch):\n",
        "        for conv in self.convs:\n",
        "            x = conv(x, edge_index).relu()\n",
        "        x = global_max_pool(x, batch)\n",
        "        x = self.mlp(x)\n",
        "\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "\n",
        "class NetSmall(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.convs = torch.nn.ModuleList()\n",
        "\n",
        "        input_channels = dataset.num_node_features\n",
        "\n",
        "        mlp = MLP([input_channels, 64])\n",
        "        self.convs.append(GINConv(nn=mlp, train_eps=False))\n",
        "        mlp = MLP([64, 64])\n",
        "        self.convs.append(GINConv(nn=mlp, train_eps=False))\n",
        "\n",
        "        self.mlp = MLP([64, dataset.num_classes])\n",
        "\n",
        "    def forward(self, x, edge_index, batch):\n",
        "        for conv in self.convs:\n",
        "            x = conv(x, edge_index).relu()\n",
        "        x = global_max_pool(x, batch)\n",
        "        x = self.mlp(x)\n",
        "\n",
        "        return F.log_softmax(x, dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for model, name in zip([NetLarge(), NetSmall()], ['NetLarge', 'NetSmall']):\n",
        "    \n",
        "    model = model.to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
        "\n",
        "    for epoch in range(1, 101):\n",
        "        train_loss = train(epoch, model, optimizer)\n",
        "\n",
        "    train_acc = test(train_loader, model)\n",
        "    test_acc = test(test_loader, model)\n",
        "\n",
        "    print(f'model = {name}')\n",
        "    print('Train Loss: {:.7f}, '\n",
        "        'Train Acc: {:.7f}, Test Acc: {:.7f}'.format(train_loss,\n",
        "                                                train_acc, test_acc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1BeM-0p0ztt6",
        "outputId": "441b91ed-1167-4490-fa47-f76317de257f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model = NetLarge\n",
            "Train Loss: 0.0712441, Train Acc: 0.9162996, Test Acc: 0.6400000\n",
            "model = NetSmall\n",
            "Train Loss: 0.4026426, Train Acc: 0.8208517, Test Acc: 0.6533333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PNumRnJ4gKrJ"
      },
      "source": [
        "## Task 3.5"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Analysis: accuracy of NetLarge and NetSmall on the test set are equal, and the NetLarge better fits the train set. As a result, less sophisticated GINs can be as expressive as very complex GINs."
      ],
      "metadata": {
        "id": "pIej1DO25Dzz"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CuSsXScqgKrK"
      },
      "source": [
        "## Task 4\n",
        "\n",
        "Done in a separate notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UOGmeeI8gKrL"
      },
      "source": [
        "# Task 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pNeV07RWgKrM"
      },
      "source": [
        "## Task 5.1"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let $\\mathcal{G}=\\left\\{\\right.$ graphlet $_1$, graphlet $_2, \\ldots$, graphlet $\\left._r\\right\\}$ be the set of size- $k$ graphlets. \n",
        "Let also $f_G \\in \\mathbb{N}^r$ be a vector such that its $i$-th entry is equal to the frequency of occurrence of graphlet $_i$ in $G$, $f_{G, i}=\\#\\left(\\right.$ graphlet $\\left._i \\sqsubseteq G\\right)$. \n",
        "$f_G$ is the representation we are looking for."
      ],
      "metadata": {
        "id": "66367asoDaQ5"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iDmyq4rzgKrM"
      },
      "source": [
        "## Task 5.2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CYqFJ5PmgKrM"
      },
      "source": [
        "## Task 5.3"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "$r_X(G_1) = [2, 2]$, $r_X(G_2) = [1, 1]$\n",
        "\n",
        "$k_X(G_1, G_2) = 2 * 1 + 2 * 1 = 4$"
      ],
      "metadata": {
        "id": "8WfFAIbSESHW"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}