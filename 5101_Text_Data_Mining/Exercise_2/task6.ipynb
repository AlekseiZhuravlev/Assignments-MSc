{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3g_sn7BMUOhe"
      },
      "outputs": [],
      "source": [
        "import requests, sklearn, numpy as np, json, pandas as pd\n",
        "from tensorflow.keras.layers import TextVectorization\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_dataset(split):\n",
        "  \"\"\"\n",
        "  split: 'train', 'test', 'validation'\n",
        "  \"\"\"\n",
        "  res = requests.get(f\"https://datasets-server.huggingface.co/first-rows?dataset=conll2003&config=conll2003&split={split}\")\n",
        "  data_raw = res.content.decode(\"utf-8\") \n",
        "  data = json.loads(data_raw)\n",
        "  rows = [row['row'] for row in data['rows']]\n",
        "  df = pd.DataFrame(rows)\n",
        "  return df"
      ],
      "metadata": {
        "id": "rptyjTbOUU9j"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# getting train/test datasets\n",
        "\n",
        "df_train = get_dataset('train')\n",
        "df_validation = get_dataset('validation')\n",
        "df_test = get_dataset('test')\n",
        "\n",
        "df_train.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "id": "8WgbKurrUcpo",
        "outputId": "686a0a23-9a15-47db-92f2-dd6903788d1d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  id                                             tokens  \\\n",
              "0  0  [EU, rejects, German, call, to, boycott, Briti...   \n",
              "1  1                                 [Peter, Blackburn]   \n",
              "2  2                             [BRUSSELS, 1996-08-22]   \n",
              "3  3  [The, European, Commission, said, on, Thursday...   \n",
              "4  4  [Germany, 's, representative, to, the, Europea...   \n",
              "\n",
              "                                            pos_tags  \\\n",
              "0                [22, 42, 16, 21, 35, 37, 16, 21, 7]   \n",
              "1                                           [22, 22]   \n",
              "2                                           [22, 11]   \n",
              "3  [12, 22, 22, 38, 15, 22, 28, 38, 15, 16, 21, 3...   \n",
              "4  [22, 27, 21, 35, 12, 22, 22, 27, 16, 21, 22, 2...   \n",
              "\n",
              "                                          chunk_tags  \\\n",
              "0                [11, 21, 11, 12, 21, 22, 11, 12, 0]   \n",
              "1                                           [11, 12]   \n",
              "2                                           [11, 12]   \n",
              "3  [11, 12, 12, 21, 13, 11, 11, 21, 13, 11, 12, 1...   \n",
              "4  [11, 11, 12, 13, 11, 12, 12, 11, 12, 12, 12, 1...   \n",
              "\n",
              "                                            ner_tags  \n",
              "0                        [3, 0, 7, 0, 0, 0, 7, 0, 0]  \n",
              "1                                             [1, 2]  \n",
              "2                                             [5, 0]  \n",
              "3  [0, 3, 4, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, ...  \n",
              "4  [5, 0, 0, 0, 0, 3, 4, 0, 0, 0, 1, 2, 0, 0, 0, ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-078e13dd-3c20-4cb6-9836-12e7a58217cd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>tokens</th>\n",
              "      <th>pos_tags</th>\n",
              "      <th>chunk_tags</th>\n",
              "      <th>ner_tags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>[EU, rejects, German, call, to, boycott, Briti...</td>\n",
              "      <td>[22, 42, 16, 21, 35, 37, 16, 21, 7]</td>\n",
              "      <td>[11, 21, 11, 12, 21, 22, 11, 12, 0]</td>\n",
              "      <td>[3, 0, 7, 0, 0, 0, 7, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>[Peter, Blackburn]</td>\n",
              "      <td>[22, 22]</td>\n",
              "      <td>[11, 12]</td>\n",
              "      <td>[1, 2]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>[BRUSSELS, 1996-08-22]</td>\n",
              "      <td>[22, 11]</td>\n",
              "      <td>[11, 12]</td>\n",
              "      <td>[5, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>[The, European, Commission, said, on, Thursday...</td>\n",
              "      <td>[12, 22, 22, 38, 15, 22, 28, 38, 15, 16, 21, 3...</td>\n",
              "      <td>[11, 12, 12, 21, 13, 11, 11, 21, 13, 11, 12, 1...</td>\n",
              "      <td>[0, 3, 4, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>[Germany, 's, representative, to, the, Europea...</td>\n",
              "      <td>[22, 27, 21, 35, 12, 22, 22, 27, 16, 21, 22, 2...</td>\n",
              "      <td>[11, 11, 12, 13, 11, 12, 12, 11, 12, 12, 12, 1...</td>\n",
              "      <td>[5, 0, 0, 0, 0, 3, 4, 0, 0, 0, 1, 2, 0, 0, 0, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-078e13dd-3c20-4cb6-9836-12e7a58217cd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-078e13dd-3c20-4cb6-9836-12e7a58217cd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-078e13dd-3c20-4cb6-9836-12e7a58217cd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# converting list of sentences into one long sequence of words\n",
        "\n",
        "def flatten(l):\n",
        "    return np.asarray([item for sublist in l for item in sublist])\n",
        "\n",
        "def lowercase(l):\n",
        "    return np.asarray([word.lower() for word in l])\n",
        "\n",
        "def make_X_y(df):\n",
        "  X_sentences = df['tokens'].to_numpy()\n",
        "  y_sentences = df['ner_tags'].to_numpy()\n",
        "  \n",
        "  # X = np.asarray([np.asarray(i) for i in X_sentences])\n",
        "  X = lowercase(flatten(X_sentences))\n",
        "  y = flatten(y_sentences)\n",
        "  y = tf.one_hot(y, 9)\n",
        "\n",
        "  return X, y\n",
        "\n",
        "X_train, y_train = make_X_y(df_train)\n",
        "X_val, y_val = make_X_y(df_validation)\n",
        "X_test, y_test = make_X_y(df_test)\n",
        "\n",
        "X_full = np.concatenate([X_train, X_val, X_test])\n",
        "\n",
        "print(X_train[:5])\n",
        "print(y_train[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "WcH58MYI612s",
        "outputId": "52f24dc4-ddef-4d96-bb7d-84fadcb70771"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['eu' 'rejects' 'german' 'call' 'to']\n",
            "tf.Tensor(\n",
            "[[0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0.]], shape=(5, 9), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# downloading glove\n",
        "\n",
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip -q glove.6B.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "mr_2zJ9384Jh",
        "outputId": "26adfe4e-1e74-4532-e16f-b5f6ac334230"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-12-15 08:58:51--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2022-12-15 08:58:51--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2022-12-15 08:58:51--  https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip.1’\n",
            "\n",
            "glove.6B.zip.1       10%[=>                  ]  84.32M  4.98MB/s    eta 1m 50s ^C\n",
            "replace glove.6B.50d.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "XNAs3NTNoNES",
        "outputId": "b1c5a7ae-bc47-4b96-ea5b-9404d37d01da"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "glove.6B.100d.txt  glove.6B.300d.txt  glove.6B.zip    sample_data\n",
            "glove.6B.200d.txt  glove.6B.50d.txt   glove.6B.zip.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# make a dict mapping words (strings) to their NumPy vector representation\n",
        "\n",
        "path_to_glove_file = \"glove.6B.100d.txt\"\n",
        "\n",
        "embeddings_index = {}\n",
        "with open(path_to_glove_file) as f:\n",
        "    for line in f:\n",
        "        word, coefs = line.split(maxsplit=1)\n",
        "        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
        "        embeddings_index[word] = coefs\n",
        "\n",
        "print(\"Found %s word vectors.\" % len(embeddings_index))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "VUrR1k7JnLHi",
        "outputId": "84dd48c6-c0c5-4fd5-f7c5-fc59ca82be2a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 400000 word vectors.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = TextVectorization(max_tokens=20000)\n",
        "text_ds = tf.data.Dataset.from_tensor_slices(X_full).batch(128)\n",
        "vectorizer.adapt(X_full)\n",
        "print(vectorizer.get_vocabulary()[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "5kcJ3fJ8oE5Q",
        "outputId": "d42b2bbd-86f5-42ed-ec11-f254101db3c2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['', '[UNK]', 'the', 'to', 'a']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# let's see how the vectorized sentence looks like\n",
        "\n",
        "for i in range(15):\n",
        "  output = vectorizer([[X_train[i]]])\n",
        "  print(X_train[i], y_train[i], output.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "SkB6igMypzBH",
        "outputId": "8eb583c6-3175-421d-e4af-0cad6b642fe0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eu tf.Tensor([0. 0. 0. 1. 0. 0. 0. 0. 0.], shape=(9,), dtype=float32) [[129]]\n",
            "rejects tf.Tensor([1. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(9,), dtype=float32) [[803]]\n",
            "german tf.Tensor([0. 0. 0. 0. 0. 0. 0. 1. 0.], shape=(9,), dtype=float32) [[71]]\n",
            "call tf.Tensor([1. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(9,), dtype=float32) [[527]]\n",
            "to tf.Tensor([1. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(9,), dtype=float32) [[3]]\n",
            "boycott tf.Tensor([1. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(9,), dtype=float32) [[1290]]\n",
            "british tf.Tensor([0. 0. 0. 0. 0. 0. 0. 1. 0.], shape=(9,), dtype=float32) [[72]]\n",
            "lamb tf.Tensor([1. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(9,), dtype=float32) [[252]]\n",
            ". tf.Tensor([1. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(9,), dtype=float32) []\n",
            "peter tf.Tensor([0. 1. 0. 0. 0. 0. 0. 0. 0.], shape=(9,), dtype=float32) [[395]]\n",
            "blackburn tf.Tensor([0. 0. 1. 0. 0. 0. 0. 0. 0.], shape=(9,), dtype=float32) [[532]]\n",
            "brussels tf.Tensor([0. 0. 0. 0. 0. 1. 0. 0. 0.], shape=(9,), dtype=float32) [[1279]]\n",
            "1996-08-22 tf.Tensor([1. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(9,), dtype=float32) [[64]]\n",
            "the tf.Tensor([1. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(9,), dtype=float32) [[2]]\n",
            "european tf.Tensor([0. 0. 0. 1. 0. 0. 0. 0. 0.], shape=(9,), dtype=float32) [[128]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# making the word index\n",
        "\n",
        "voc = vectorizer.get_vocabulary()\n",
        "word_index = dict(zip(voc, range(len(voc))))"
      ],
      "metadata": {
        "id": "JxTsM9mQqhNi"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_tokens = len(voc) + 2\n",
        "embedding_dim = 100\n",
        "hits = 0\n",
        "misses = 0\n",
        "\n",
        "# Prepare embedding matrix\n",
        "embedding_matrix = np.zeros((num_tokens, embedding_dim))\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        # Words not found in embedding index will be all-zeros.\n",
        "        # This includes the representation for \"padding\" and \"OOV\"\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "        hits += 1\n",
        "    else:\n",
        "        misses += 1\n",
        "print(\"Converted %d words (%d misses)\" % (hits, misses))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "FnxbqhAsqH8p",
        "outputId": "ca2fb716-e4c6-4ce4-971a-651f40087b56"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converted 1406 words (111 misses)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Embedding\n",
        "import keras\n",
        "\n",
        "# create the embedding layer\n",
        "embedding_layer = Embedding(\n",
        "    num_tokens,\n",
        "    embedding_dim,\n",
        "    embeddings_initializer=keras.initializers.Constant(embedding_matrix),\n",
        "    trainable=False,\n",
        ")"
      ],
      "metadata": {
        "id": "9HhRrLRLqi5h"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "# build the model\n",
        "int_sequences_input = keras.Input(shape=(1,))\n",
        "embedded_sequences = embedding_layer(int_sequences_input)\n",
        "\n",
        "# Add 2 bidirectional LSTMs\n",
        "x = layers.LSTM(64)(embedded_sequences)\n",
        "# x = layers.LSTM(64)(x)\n",
        "# Add a classifier\n",
        "outputs = layers.Dense(9, activation=\"sigmoid\")(x)\n",
        "model = keras.Model(int_sequences_input, outputs)\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "HtBtKrnxxdIP",
        "outputId": "2a2fe160-228d-4401-d136-9f8adefe2d26"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 1, 100)            151900    \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 64)                42240     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 9)                 585       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 194,725\n",
            "Trainable params: 42,825\n",
            "Non-trainable params: 151,900\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert our word data to NumPy arrays of integer indices\n",
        "\n",
        "X_train_indices = vectorizer(np.array([[s] for s in X_train])).numpy()\n",
        "X_val_indices = vectorizer(np.array([[s] for s in X_val])).numpy()\n",
        "X_test_indices = vectorizer(np.array([[s] for s in X_test])).numpy()\n",
        "\n",
        "# example of training data\n",
        "for i in zip(X_train[0:10], X_train_indices[0:10]):\n",
        "  print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "QrlxLKxAqv92",
        "outputId": "5567c1ee-c2dc-4e70-8bac-da04c8d0c2ac"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "('eu', array([129]))\n",
            "('rejects', array([803]))\n",
            "('german', array([71]))\n",
            "('call', array([527]))\n",
            "('to', array([3]))\n",
            "('boycott', array([1290]))\n",
            "('british', array([72]))\n",
            "('lamb', array([252]))\n",
            "('.', array([0]))\n",
            "('peter', array([395]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\"adam\", \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "history = model.fit(X_train_indices, y_train, epochs=100,\n",
        "          validation_data=(X_val_indices, y_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "kNoKv_2krYiK",
        "outputId": "a2ba3b13-ad43-428f-d758-a731fa15aefc"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "52/52 [==============================] - 3s 17ms/step - loss: 0.4925 - accuracy: 0.7428 - val_loss: 0.3357 - val_accuracy: 0.7911\n",
            "Epoch 2/100\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.2399 - accuracy: 0.8412 - val_loss: 0.2523 - val_accuracy: 0.7926\n",
            "Epoch 3/100\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.1905 - accuracy: 0.8430 - val_loss: 0.2279 - val_accuracy: 0.7985\n",
            "Epoch 4/100\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.1642 - accuracy: 0.8490 - val_loss: 0.2099 - val_accuracy: 0.8037\n",
            "Epoch 5/100\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.1437 - accuracy: 0.8762 - val_loss: 0.1949 - val_accuracy: 0.8126\n",
            "Epoch 6/100\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.1269 - accuracy: 0.8943 - val_loss: 0.1810 - val_accuracy: 0.8170\n",
            "Epoch 7/100\n",
            "52/52 [==============================] - 0s 7ms/step - loss: 0.1123 - accuracy: 0.9010 - val_loss: 0.1689 - val_accuracy: 0.8141\n",
            "Epoch 8/100\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.0993 - accuracy: 0.9082 - val_loss: 0.1592 - val_accuracy: 0.8170\n",
            "Epoch 9/100\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.0882 - accuracy: 0.9155 - val_loss: 0.1503 - val_accuracy: 0.8163\n",
            "Epoch 10/100\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.0786 - accuracy: 0.9245 - val_loss: 0.1431 - val_accuracy: 0.8170\n",
            "Epoch 11/100\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.0704 - accuracy: 0.9300 - val_loss: 0.1384 - val_accuracy: 0.8207\n",
            "Epoch 12/100\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.0636 - accuracy: 0.9342 - val_loss: 0.1324 - val_accuracy: 0.8185\n",
            "Epoch 13/100\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.0579 - accuracy: 0.9384 - val_loss: 0.1294 - val_accuracy: 0.8215\n",
            "Epoch 14/100\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.0532 - accuracy: 0.9420 - val_loss: 0.1278 - val_accuracy: 0.8096\n",
            "Epoch 15/100\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.0492 - accuracy: 0.9420 - val_loss: 0.1258 - val_accuracy: 0.8096\n",
            "Epoch 16/100\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.0458 - accuracy: 0.9444 - val_loss: 0.1241 - val_accuracy: 0.8081\n",
            "Epoch 17/100\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.0430 - accuracy: 0.9511 - val_loss: 0.1241 - val_accuracy: 0.8074\n",
            "Epoch 18/100\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.0405 - accuracy: 0.9529 - val_loss: 0.1231 - val_accuracy: 0.8081\n",
            "Epoch 19/100\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.0384 - accuracy: 0.9541 - val_loss: 0.1229 - val_accuracy: 0.8052\n",
            "Epoch 20/100\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.0365 - accuracy: 0.9583 - val_loss: 0.1238 - val_accuracy: 0.8104\n",
            "Epoch 21/100\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.0347 - accuracy: 0.9589 - val_loss: 0.1231 - val_accuracy: 0.8111\n",
            "Epoch 22/100\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.0332 - accuracy: 0.9632 - val_loss: 0.1244 - val_accuracy: 0.8111\n",
            "Epoch 23/100\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.0318 - accuracy: 0.9650 - val_loss: 0.1250 - val_accuracy: 0.8119\n",
            "Epoch 24/100\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.0306 - accuracy: 0.9668 - val_loss: 0.1254 - val_accuracy: 0.8133\n",
            "Epoch 25/100\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.0295 - accuracy: 0.9680 - val_loss: 0.1244 - val_accuracy: 0.8096\n",
            "Epoch 26/100\n",
            "52/52 [==============================] - 0s 7ms/step - loss: 0.0284 - accuracy: 0.9686 - val_loss: 0.1262 - val_accuracy: 0.8119\n",
            "Epoch 27/100\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.0276 - accuracy: 0.9704 - val_loss: 0.1282 - val_accuracy: 0.8141\n",
            "Epoch 28/100\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.0265 - accuracy: 0.9698 - val_loss: 0.1273 - val_accuracy: 0.8141\n",
            "Epoch 29/100\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.0258 - accuracy: 0.9716 - val_loss: 0.1282 - val_accuracy: 0.8163\n",
            "Epoch 30/100\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.0248 - accuracy: 0.9734 - val_loss: 0.1279 - val_accuracy: 0.8133\n",
            "Epoch 31/100\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.0241 - accuracy: 0.9740 - val_loss: 0.1307 - val_accuracy: 0.8178\n",
            "Epoch 32/100\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.0236 - accuracy: 0.9740 - val_loss: 0.1295 - val_accuracy: 0.8193\n",
            "Epoch 33/100\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.0229 - accuracy: 0.9734 - val_loss: 0.1303 - val_accuracy: 0.8193\n",
            "Epoch 34/100\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.0223 - accuracy: 0.9764 - val_loss: 0.1302 - val_accuracy: 0.8156\n",
            "Epoch 35/100\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.0218 - accuracy: 0.9752 - val_loss: 0.1316 - val_accuracy: 0.8200\n",
            "Epoch 36/100\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.0213 - accuracy: 0.9764 - val_loss: 0.1335 - val_accuracy: 0.8215\n",
            "Epoch 37/100\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.0207 - accuracy: 0.9764 - val_loss: 0.1339 - val_accuracy: 0.8207\n",
            "Epoch 38/100\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.0203 - accuracy: 0.9758 - val_loss: 0.1332 - val_accuracy: 0.8215\n",
            "Epoch 39/100\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.0199 - accuracy: 0.9764 - val_loss: 0.1337 - val_accuracy: 0.8215\n",
            "Epoch 40/100\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.0195 - accuracy: 0.9764 - val_loss: 0.1344 - val_accuracy: 0.8215\n",
            "Epoch 41/100\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.0193 - accuracy: 0.9764 - val_loss: 0.1348 - val_accuracy: 0.8215\n",
            "Epoch 42/100\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.0189 - accuracy: 0.9764 - val_loss: 0.1363 - val_accuracy: 0.8215\n",
            "Epoch 43/100\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.0186 - accuracy: 0.9783 - val_loss: 0.1343 - val_accuracy: 0.8170\n",
            "Epoch 44/100\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.0182 - accuracy: 0.9783 - val_loss: 0.1379 - val_accuracy: 0.8215\n",
            "Epoch 45/100\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.0180 - accuracy: 0.9771 - val_loss: 0.1367 - val_accuracy: 0.8222\n",
            "Epoch 46/100\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.0177 - accuracy: 0.9789 - val_loss: 0.1368 - val_accuracy: 0.8230\n",
            "Epoch 47/100\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.0174 - accuracy: 0.9783 - val_loss: 0.1381 - val_accuracy: 0.8237\n",
            "Epoch 48/100\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.0172 - accuracy: 0.9777 - val_loss: 0.1373 - val_accuracy: 0.8237\n",
            "Epoch 49/100\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.0170 - accuracy: 0.9777 - val_loss: 0.1384 - val_accuracy: 0.8244\n",
            "Epoch 50/100\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.0167 - accuracy: 0.9783 - val_loss: 0.1387 - val_accuracy: 0.8200\n",
            "Epoch 51/100\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.0166 - accuracy: 0.9789 - val_loss: 0.1392 - val_accuracy: 0.8244\n",
            "Epoch 52/100\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.0164 - accuracy: 0.9777 - val_loss: 0.1389 - val_accuracy: 0.8215\n",
            "Epoch 53/100\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.0163 - accuracy: 0.9789 - val_loss: 0.1392 - val_accuracy: 0.8215\n",
            "Epoch 54/100\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.0160 - accuracy: 0.9801 - val_loss: 0.1405 - val_accuracy: 0.8215\n",
            "Epoch 55/100\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.0159 - accuracy: 0.9789 - val_loss: 0.1401 - val_accuracy: 0.8215\n",
            "Epoch 56/100\n",
            "52/52 [==============================] - 0s 7ms/step - loss: 0.0157 - accuracy: 0.9789 - val_loss: 0.1412 - val_accuracy: 0.8252\n",
            "Epoch 57/100\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.0156 - accuracy: 0.9789 - val_loss: 0.1425 - val_accuracy: 0.8252\n",
            "Epoch 58/100\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.0155 - accuracy: 0.9795 - val_loss: 0.1404 - val_accuracy: 0.8230\n",
            "Epoch 59/100\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.0155 - accuracy: 0.9777 - val_loss: 0.1416 - val_accuracy: 0.8222\n",
            "Epoch 60/100\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.0153 - accuracy: 0.9783 - val_loss: 0.1414 - val_accuracy: 0.8222\n",
            "Epoch 61/100\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.0152 - accuracy: 0.9777 - val_loss: 0.1410 - val_accuracy: 0.8237\n",
            "Epoch 62/100\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.0151 - accuracy: 0.9783 - val_loss: 0.1423 - val_accuracy: 0.8267\n",
            "Epoch 63/100\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.0149 - accuracy: 0.9783 - val_loss: 0.1418 - val_accuracy: 0.8244\n",
            "Epoch 64/100\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.0149 - accuracy: 0.9764 - val_loss: 0.1421 - val_accuracy: 0.8252\n",
            "Epoch 65/100\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.0147 - accuracy: 0.9783 - val_loss: 0.1428 - val_accuracy: 0.8237\n",
            "Epoch 66/100\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.0148 - accuracy: 0.9783 - val_loss: 0.1426 - val_accuracy: 0.8289\n",
            "Epoch 67/100\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.0144 - accuracy: 0.9801 - val_loss: 0.1443 - val_accuracy: 0.8274\n",
            "Epoch 68/100\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.0145 - accuracy: 0.9777 - val_loss: 0.1446 - val_accuracy: 0.8274\n",
            "Epoch 69/100\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.0144 - accuracy: 0.9764 - val_loss: 0.1435 - val_accuracy: 0.8289\n",
            "Epoch 70/100\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.0143 - accuracy: 0.9783 - val_loss: 0.1441 - val_accuracy: 0.8289\n",
            "Epoch 71/100\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.0143 - accuracy: 0.9777 - val_loss: 0.1446 - val_accuracy: 0.8252\n",
            "Epoch 72/100\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.0143 - accuracy: 0.9783 - val_loss: 0.1457 - val_accuracy: 0.8252\n",
            "Epoch 73/100\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.0141 - accuracy: 0.9783 - val_loss: 0.1454 - val_accuracy: 0.8252\n",
            "Epoch 74/100\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.0141 - accuracy: 0.9789 - val_loss: 0.1455 - val_accuracy: 0.8289\n",
            "Epoch 75/100\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.0140 - accuracy: 0.9771 - val_loss: 0.1449 - val_accuracy: 0.8267\n",
            "Epoch 76/100\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.0140 - accuracy: 0.9789 - val_loss: 0.1469 - val_accuracy: 0.8289\n",
            "Epoch 77/100\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.0139 - accuracy: 0.9771 - val_loss: 0.1462 - val_accuracy: 0.8289\n",
            "Epoch 78/100\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.0140 - accuracy: 0.9783 - val_loss: 0.1456 - val_accuracy: 0.8296\n",
            "Epoch 79/100\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.0138 - accuracy: 0.9783 - val_loss: 0.1462 - val_accuracy: 0.8259\n",
            "Epoch 80/100\n",
            "52/52 [==============================] - 0s 7ms/step - loss: 0.0137 - accuracy: 0.9777 - val_loss: 0.1472 - val_accuracy: 0.8259\n",
            "Epoch 81/100\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.0137 - accuracy: 0.9789 - val_loss: 0.1473 - val_accuracy: 0.8259\n",
            "Epoch 82/100\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.0135 - accuracy: 0.9789 - val_loss: 0.1472 - val_accuracy: 0.8296\n",
            "Epoch 83/100\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.0136 - accuracy: 0.9807 - val_loss: 0.1457 - val_accuracy: 0.8259\n",
            "Epoch 84/100\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.0135 - accuracy: 0.9758 - val_loss: 0.1468 - val_accuracy: 0.8259\n",
            "Epoch 85/100\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.0135 - accuracy: 0.9771 - val_loss: 0.1491 - val_accuracy: 0.8304\n",
            "Epoch 86/100\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.0138 - accuracy: 0.9758 - val_loss: 0.1489 - val_accuracy: 0.8296\n",
            "Epoch 87/100\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.0135 - accuracy: 0.9777 - val_loss: 0.1479 - val_accuracy: 0.8296\n",
            "Epoch 88/100\n",
            "52/52 [==============================] - 0s 7ms/step - loss: 0.0135 - accuracy: 0.9771 - val_loss: 0.1496 - val_accuracy: 0.8296\n",
            "Epoch 89/100\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.0134 - accuracy: 0.9783 - val_loss: 0.1483 - val_accuracy: 0.8296\n",
            "Epoch 90/100\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.0134 - accuracy: 0.9771 - val_loss: 0.1502 - val_accuracy: 0.8296\n",
            "Epoch 91/100\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.0134 - accuracy: 0.9783 - val_loss: 0.1485 - val_accuracy: 0.8259\n",
            "Epoch 92/100\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.0135 - accuracy: 0.9771 - val_loss: 0.1487 - val_accuracy: 0.8296\n",
            "Epoch 93/100\n",
            "52/52 [==============================] - 0s 7ms/step - loss: 0.0132 - accuracy: 0.9801 - val_loss: 0.1487 - val_accuracy: 0.8274\n",
            "Epoch 94/100\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.0132 - accuracy: 0.9783 - val_loss: 0.1494 - val_accuracy: 0.8259\n",
            "Epoch 95/100\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.0133 - accuracy: 0.9795 - val_loss: 0.1478 - val_accuracy: 0.8274\n",
            "Epoch 96/100\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.0132 - accuracy: 0.9777 - val_loss: 0.1503 - val_accuracy: 0.8304\n",
            "Epoch 97/100\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.0131 - accuracy: 0.9771 - val_loss: 0.1488 - val_accuracy: 0.8296\n",
            "Epoch 98/100\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.0132 - accuracy: 0.9777 - val_loss: 0.1496 - val_accuracy: 0.8259\n",
            "Epoch 99/100\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.0134 - accuracy: 0.9771 - val_loss: 0.1477 - val_accuracy: 0.8274\n",
            "Epoch 100/100\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.0131 - accuracy: 0.9771 - val_loss: 0.1504 - val_accuracy: 0.8259\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "5Nj3mKsfy3Up",
        "outputId": "f0cde817-2735-428c-b6ae-2bfa2fbf1731"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# accuracy on the test set\n",
        "\n",
        "metric_accuracy = tf.keras.metrics.Accuracy()\n",
        "predictions = model.predict(X_test_indices)\n",
        "\n",
        "metric_accuracy.update_state(tf.argmax(predictions, 1), tf.argmax(y_test,1))\n",
        "metric_accuracy.result().numpy()\n"
      ],
      "metadata": {
        "id": "S4M00UV56x_p",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "b64db1dc-bf67-47bf-a7e2-c2d57bfccc48"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "45/45 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.84388185"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise 6.2\n",
        "\n",
        "The advantage of using RNN is that they have internal state and can renember previous input. This is useful because named entities often come in specific context, i.e. preceded by 'the': 'the EU'"
      ],
      "metadata": {
        "id": "qeQnScrmFuCz"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Dd5HT9_MBnmS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}