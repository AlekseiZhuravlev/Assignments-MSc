{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd523a39",
   "metadata": {
    "id": "fd523a39"
   },
   "source": [
    "# Introduction to Natural Language Processing: Assignment 5\n",
    "\n",
    "In this exercise, we'll practice the implementation of the Viterbi Algorithm for the Hidden Markov Model.\n",
    "\n",
    "- You can use built-in Python packages, spaCy, scikit-learn, Numpy and Pandas.\n",
    "- Please comment your code\n",
    "- Submissions are due Tuesdays at 23:59 **only** on eCampus: **Assignmnets >> Student Submissions >> Assignment 5 (Deadline: 16.01.2024, at 23:59)**\n",
    "\n",
    "- Name the file aproppriately: \"Assignment_5_\\<Your_Name\\>.ipynb\" and submit only the Jupyter Notebook file.\n",
    "- Please use relative path, your code should work on my computer if the Jupyter Notebook and the file are both in the same directory.\n",
    "\n",
    "Example: file_name = emission_probabilities.csv, **DON'T use:** /Users/ComputerName/Username/Documents/.../emission_probabilities.csv\n",
    "\n",
    "**Notes:**\n",
    "\n",
    "1. For this exercise, please follow the lecture and exercise slides. Additionally, you can refer to the YouTube-links mentioned in the slides, e.g., Lecture 8 >> Page 30 or this one: [LINK](https://www.youtube.com/watch?v=IqXdjdOgXPM)\n",
    "2. Reference for Viterbi algorithm in Task 2: [LINK](https://web.stanford.edu/~jurafsky/slp3/A.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f148dd",
   "metadata": {
    "id": "b7f148dd"
   },
   "source": [
    "### Task 1 (6 points)\n",
    "\n",
    "\n",
    "Using the files `transisition_probabilities.csv` and `emission_probabilities.csv`, compute the probability of POS tags for the following word sequence:\n",
    "\n",
    "| I | want | to | race |\n",
    "| --|------|----|------|\n",
    "\n",
    "Import the given files and:\n",
    "\n",
    "**a)** Define a function (all_possible_tags) to retrieve **ALL possible tag sequences** for the given word sequence.\n",
    "\n",
    "**Input:**  Sentence (\"I want to race\") and the files above.\n",
    "\n",
    "**Output:** All possible tag sequences. >> `all_possible_tags_dict = {\"1\": [VB, TO, NN, PPSS], \"2\": [NN, TO, VB, PPSS], \"3\": ...}`)\n",
    "\n",
    "**b)** Define a function (all_possible_tags_probability) to select the most probable tag sequence.\n",
    "\n",
    "**Input:** All possible tag sequences retrieved in (a) and the files above\n",
    "\n",
    "**Output:** The probability for each possible tag sequence as well as the most probable tag sequence with its probability. >> `all_possible_tags_probability_dict = {\"1\": 0.00123, \"2\": 0.00234, \"3\": ...}` and `most_probable_tag_seq_dict = {tag_sequence: [VB, TO, NN, PPSS], probability: 0.00123}`\n",
    "\n",
    "**Notes:**\n",
    "1. The indices of the output in (b) should represent the same indices of the output in (a).\n",
    "2. The tag sequences and the probabilities, shown above in (a) and (b), are only some random examples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3fff41",
   "metadata": {
    "id": "5a3fff41"
   },
   "outputs": [],
   "source": [
    "def all_possible_tags(sentence, emission_probabilities):\n",
    "\n",
    "    all_possible_tags_dict = {}\n",
    "    #Here comes your code\n",
    "\n",
    "    return(all_possible_tags_dict)\n",
    "\n",
    "def all_possible_tags_probability(sentence, all_possible_tags_dict, transisition_probabilities, emission_probabilities):\n",
    "\n",
    "    all_possible_tags_probability_dict = {}\n",
    "    most_probable_tag_seq_dict = {}\n",
    "    #Here comes your code\n",
    "\n",
    "    return(possible_tags_probability_dict, most_probable_tag_seq_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb6b483",
   "metadata": {
    "id": "bdb6b483"
   },
   "source": [
    "### Task 2 (7 points)\n",
    "\n",
    "Implement the following algorithm from scratch, using the files given for Task 1:\n",
    "\n",
    " ![VITERBI.png](\\VITERBI.png)\n",
    "\n",
    "\n",
    "You should define a function (viterbi) that:\n",
    "\n",
    "**a)** Computes the initialization step.\n",
    "\n",
    "**b)** Computes the recursion step.\n",
    "\n",
    "**c)** Computes the termination step.\n",
    "\n",
    "**Input:** Sentence (\"I want to race\"), transition and emission files.\n",
    "\n",
    "**Output:** Most probable tag sequence and its probability. >> `most_probable_tag_seq_dict = {tag_sequence: [VB, TO, NN, PPSS], probability: 0.00123}`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50764f3a",
   "metadata": {
    "id": "50764f3a"
   },
   "outputs": [],
   "source": [
    "def viterbi(sentence, transisition_probabilities, emission_probabilities):\n",
    "\n",
    "    most_probable_tag_seq_dict = {}\n",
    "    #Here comes your code\n",
    "\n",
    "    return(most_probable_tag_seq_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TxACt7OmK4rI"
   },
   "source": [
    "## Task 3 (7 points)\n",
    "\n",
    "Given a hidden markov model with the following probabilities:\n",
    "\n",
    "**Transition Probabilities:**\n",
    "\n",
    "\n",
    " |            | Sunny (S) | Cloudy (C) | Rainy (R)       |\n",
    "-------------|------------|-----------|---------------\n",
    "|Sunny (S)    | 0.7       | 0.2        | 0.1   |\n",
    "|Cloudy (C)   | 0.3       | 0.5        | 0.2   |\n",
    "|Rainy (R)    | 0.1       | 0.4        | 0.5   |\n",
    "\n",
    "**Emission Probabilities:**\n",
    "\n",
    " |            | Dry (D)    | Wet (W) |\n",
    "-------------|------------|------------\n",
    "|Sunny (S)    | 0.9        | 0.1    |\n",
    "|Cloudy (C)   | 0.6        | 0.4     |\n",
    "|Rainy (R)    | 0.2        | 0.8     |\n",
    "\n",
    "**Initial Probability Distribution:**\n",
    "\n",
    "\n",
    "Sunny (S): 0.4\n",
    "\n",
    "Cloudy (C): 0.3\n",
    "\n",
    "Rainy (R): 0.3\n",
    "\n",
    "represented in following graph: the colored, straight arrows represent values of Transition Matrix, the dotted arrows represent the Emission Matrix while the arrows from the start node to the hidden states (Sunny, Cloudy, Rainy) represent the initial probabilities.\n",
    "\n",
    " ![HMM.png](\\HMM.png)\n",
    "\n",
    "\n",
    "**1)** Compute the probabilities of observing the sequence Dry, Wet, Wet, Dry given this hidden state sequence Sunny, Cloudy, Rainy, Sunny.\n",
    "\n",
    "**2)**  How would the hidden Markov model (HMM) be affected if the emission probabilities for the observation symbols 'Dry' and 'Wet' in the Sunny state were both 0.5? Discuss the potential implications on the model's behavior and the interpretation of the observation sequence in part 1.\n",
    "\n",
    "**Note:**  You can type your solution directly in the following Markdown or add a handwritten image to it. Don't forget to submit the image if you choose that option."
   ],
   "id": "TxACt7OmK4rI"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i-FOy0ytK4rI"
   },
   "source": [
    "Here comes your solution\n"
   ],
   "id": "i-FOy0ytK4rI"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "colab": {
   "provenance": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
