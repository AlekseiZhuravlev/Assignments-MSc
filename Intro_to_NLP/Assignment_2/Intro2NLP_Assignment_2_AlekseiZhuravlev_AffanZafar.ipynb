{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92073528",
   "metadata": {
    "id": "92073528"
   },
   "source": [
    "# Introduction to Natural Language Processing: Assignment 2\n",
    "\n",
    "In this exercise we'll practice training and testing classifiers.\n",
    "\n",
    "- You can use any built-in Python packages, scikit-learn and Pandas.\n",
    "- Please comment your code\n",
    "- Submissions are due Thursday at 23:59 and should be submitted **ONLY** on eCampus: **Assignmnets >> Student Submissions >> Assignment 2 (Deadline: 21.11.2023, at 23:59)**\n",
    "- Name the file aproppriately \"Assignment_2_\\<Your_Name\\>.ipynb\".\n",
    "- Please use relative paths, your code should run on my computer if the notebook and the file are both in the same directory.\n",
    "\n",
    "Example: file_name = polarity.txt >> **DON'T use:** /Users/ComputerName/Username/Documents/.../polarity.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef5be54",
   "metadata": {
    "id": "7ef5be54"
   },
   "source": [
    "### Task 1.1 (2 point)\n",
    "\n",
    "Create a DataFrame using the `polarity.txt` file and give name to the columns appropriately. (e.g., \"Text\", \"Label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a259fbec",
   "metadata": {
    "id": "a259fbec"
   },
   "outputs": [],
   "source": [
    "#here comes your code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b505bc8",
   "metadata": {
    "id": "7b505bc8"
   },
   "source": [
    "### Task 1.2 (2 point)\n",
    "\n",
    "Create a new column for the DataFrame that contains labels converted to numerical values instead of strings using the function: `apply()` and drop the original column afterwards.\n",
    "\n",
    "Hint: The numarical values can be any meaningful values, e.g., pos >> 1 and neg >> 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b671658",
   "metadata": {
    "id": "0b671658"
   },
   "outputs": [],
   "source": [
    "# here comes your code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53dcdd4c",
   "metadata": {
    "id": "53dcdd4c"
   },
   "source": [
    "### Task 2 (8 points)\n",
    "\n",
    "Write a function `create_count_and_probability` that takes a file (`corpus.txt`) as input and returns a csv file as output containing three columns:\n",
    "1. Text\n",
    "2. Count_Vector\n",
    "3. Probability\n",
    "\n",
    "Example:\n",
    "\n",
    "For the line: `This document is the second document.`\n",
    "\n",
    "The row in the csv file should contain:\n",
    "`This document is the second document.`   `[0,2,0,1,0,1,1,0,1]`   `[1/6, 2/6, 1/6, 1/6, 1/6, 2/6]`\n",
    "\n",
    "**Note**:\n",
    "\n",
    "1. You should define your own function and not use e.g., CountVectorizer() which gives you the `count vector`, directly.\n",
    "\n",
    "2. You can either use the whitespace in `split` as the seperator or use the `Regular Expression (re)` to extract the words, as follows:\n",
    "\n",
    "```\n",
    "import re\n",
    "TEXT = \"Hey, - How are you doing today!?\"\n",
    "words_list = re.findall(r\"[\\w']+\", TEXT)\n",
    "print(words_list)\n",
    "```\n",
    "\n",
    "3. To count the words, you can use e.g., the library: `collections`, more specifically `Counter`.\n",
    "\n",
    "4. Please don't upload the output file. Your function should generate the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a09321",
   "metadata": {
    "id": "a1a09321"
   },
   "outputs": [],
   "source": [
    "def create_count_and_probability(file_name):\n",
    "    # here comes your code\n",
    "    return(csv_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c56eef-5e75-41b5-a05c-f68d0b7d98fd",
   "metadata": {
    "id": "41c56eef-5e75-41b5-a05c-f68d0b7d98fd"
   },
   "source": [
    "### Task 3 (8 points)\n",
    "\n",
    "The goal of this task is to train and test classifiers provided in scikit-learn, using two datasets `rural.txt` and `science.txt`.\n",
    "\n",
    "a) Each file (rural and science) contains sentence-wise documents. You should create a dataframe containing two columns: \"Document\" and \" Class\", as shown below. This dataframe will be used later as input for the vectorizer.\n",
    "\n",
    "|Document                             |Class |\n",
    "| ------------------------------------|----- |\n",
    "|PM denies knowledge of AWB kickbacks | rural |\n",
    "|The crocodile ancestor fossil, found...| science |\n",
    "\n",
    "\n",
    "b) Split the data into train (70%) and test (30%) sets and use the tf-idf-vectorizer to train following classifiers provided by scikit-learn:\n",
    "\n",
    "- naive_bayes.GaussianNB()\n",
    "- svm.LinearSVC().\n",
    "\n",
    "c) Evaluate both classifiers using the test set, report accuracy, recall, precision, f1 scores and confusion matrix.\n",
    "\n",
    "**Hints:**\n",
    "1. The Gaussian NB Classifier takes a dense matrix as input and the output of the vectorizer is a sparse matrix. Use my_matrix.toarray() for this conversion.\n",
    "2. You can play around with various parameters in both the tf-idf-vectorizer and the classifier to get a better performance in terms of the accuracy. (In the exercise, we will discuss the accuracy of your model.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f4b527a-0d04-4a0e-9281-fec9e0cd0ec0",
   "metadata": {
    "id": "4f4b527a-0d04-4a0e-9281-fec9e0cd0ec0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PM denies knowledge of AWB kickbacks\\n', 'The Prime Minister has denied he knew AWB was paying kickbacks to Iraq despite writing to the wheat exporter asking to be kept fully informed on Iraq wheat sales.\\n', 'Letters from John Howard and Deputy Prime Minister Mark Vaile to AWB have been released by the Cole inquiry into the oil for food program.\\n', 'In one of the letters Mr Howard asks AWB managing director Andrew Lindberg to remain in close contact with the Government on Iraq wheat sales.\\n', \"The Opposition's Gavan O'Connor says the letter was sent in 2002, the same time AWB was paying kickbacks to Iraq though a Jordanian trucking company.\\n\"]\n"
     ]
    }
   ],
   "source": [
    "# read rural.txt\n",
    "with open(\"rural.txt\", \"r\") as f:\n",
    "    rural = f.readlines()\n",
    "\n",
    "print(rural[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "                                            Document  Class\n0               PM denies knowledge of AWB kickbacks  rural\n1  The Prime Minister has denied he knew AWB was ...  rural\n2  Letters from John Howard and Deputy Prime Mini...  rural\n3  In one of the letters Mr Howard asks AWB manag...  rural\n4  The Opposition's Gavan O'Connor says the lette...  rural",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Document</th>\n      <th>Class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>PM denies knowledge of AWB kickbacks</td>\n      <td>rural</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>The Prime Minister has denied he knew AWB was ...</td>\n      <td>rural</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Letters from John Howard and Deputy Prime Mini...</td>\n      <td>rural</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>In one of the letters Mr Howard asks AWB manag...</td>\n      <td>rural</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>The Opposition's Gavan O'Connor says the lette...</td>\n      <td>rural</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Each file (rural and science) contains sentence-wise documents. You should create a dataframe containing two columns: \"Document\" and \" Class\", as shown below. This dataframe will be used later as input for the vectorizer.\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "rural = [x.strip() for x in rural]\n",
    "rural = pd.DataFrame(rural, columns = [\"Document\"])\n",
    "rural[\"Class\"] = \"rural\"\n",
    "rural.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Cystic fibrosis affects 30,000 children and young adults in the US alone\\n', 'Inhaling the mists of salt water can reduce the pus and infection that fills the airways of cystic fibrosis sufferers, although side effects include a nasty coughing fit and a harsh taste. \\n', \"That's the conclusion of two studies published in this week's issue of The New England Journal of Medicine.\\n\", 'They found that inhaling a mist with a salt content of 7 or 9% improved lung function and, in some cases, produced less absenteeism from school or work. \\n', 'Cystic fibrosis, a progressive and frequently fatal genetic disease that affects about 30,000 young adults and children in the US alone, is marked by a thickening of the mucus which makes it harder to clear the lungs of debris and bacteria. \\n']\n"
     ]
    }
   ],
   "source": [
    "# read science.txt\n",
    "with open(\"science.txt\", \"r\") as f:\n",
    "    science = f.readlines()\n",
    "\n",
    "print(science[:5])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "                                            Document    Class\n0  Cystic fibrosis affects 30,000 children and yo...  science\n1  Inhaling the mists of salt water can reduce th...  science\n2  That's the conclusion of two studies published...  science\n3  They found that inhaling a mist with a salt co...  science\n4  Cystic fibrosis, a progressive and frequently ...  science",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Document</th>\n      <th>Class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Cystic fibrosis affects 30,000 children and yo...</td>\n      <td>science</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Inhaling the mists of salt water can reduce th...</td>\n      <td>science</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>That's the conclusion of two studies published...</td>\n      <td>science</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>They found that inhaling a mist with a salt co...</td>\n      <td>science</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Cystic fibrosis, a progressive and frequently ...</td>\n      <td>science</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "science = [x.strip() for x in science]\n",
    "science = pd.DataFrame(science, columns = [\"Document\"])\n",
    "\n",
    "science[\"Class\"] = \"science\"\n",
    "science.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "                                            Document  Class\n0               PM denies knowledge of AWB kickbacks  rural\n1  The Prime Minister has denied he knew AWB was ...  rural\n2  Letters from John Howard and Deputy Prime Mini...  rural\n3  In one of the letters Mr Howard asks AWB manag...  rural\n4  The Opposition's Gavan O'Connor says the lette...  rural",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Document</th>\n      <th>Class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>PM denies knowledge of AWB kickbacks</td>\n      <td>rural</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>The Prime Minister has denied he knew AWB was ...</td>\n      <td>rural</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Letters from John Howard and Deputy Prime Mini...</td>\n      <td>rural</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>In one of the letters Mr Howard asks AWB manag...</td>\n      <td>rural</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>The Opposition's Gavan O'Connor says the lette...</td>\n      <td>rural</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concatenate the two dataframes\n",
    "df = pd.concat([rural, science], ignore_index=True)\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gnb.score 0.9080118694362018\n",
      "lsvc.score 0.9287833827893175\n"
     ]
    }
   ],
   "source": [
    "# b) Split the data into train (70%) and test (30%) sets and use the tf-idf-vectorizer to train following classifiers provided by scikit-learn:\n",
    "#- naive_bayes.GaussianNB()\n",
    "#- svm.LinearSVC().\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import svm\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[\"Document\"], df[\"Class\"], test_size=0.3, random_state=42)\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)\n",
    "\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train.toarray(), y_train)\n",
    "print('gnb.score', gnb.score(X_test.toarray(), y_test))\n",
    "\n",
    "lsvc = svm.LinearSVC()\n",
    "lsvc.fit(X_train.toarray(), y_train)\n",
    "print('lsvc.score', lsvc.score(X_test.toarray(), y_test))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####### GaussianNB #######\n",
      "score 0.9080118694362018\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       rural       0.91      0.91      0.91       174\n",
      "     science       0.91      0.90      0.90       163\n",
      "\n",
      "    accuracy                           0.91       337\n",
      "   macro avg       0.91      0.91      0.91       337\n",
      "weighted avg       0.91      0.91      0.91       337\n",
      "\n",
      "confusion matrix\n",
      " [[159  15]\n",
      " [ 16 147]]\n",
      "\n",
      "\n",
      "####### LinearSVC #######\n",
      "score 0.9287833827893175\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       rural       0.93      0.93      0.93       174\n",
      "     science       0.93      0.93      0.93       163\n",
      "\n",
      "    accuracy                           0.93       337\n",
      "   macro avg       0.93      0.93      0.93       337\n",
      "weighted avg       0.93      0.93      0.93       337\n",
      "\n",
      "confusion matrix\n",
      " [[162  12]\n",
      " [ 12 151]]\n"
     ]
    }
   ],
   "source": [
    "# c) Evaluate both classifiers using the test set, report accuracy, recall, precision, f1 scores and confusion matrix.\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "y_pred_gnb = gnb.predict(X_test.toarray())\n",
    "print('####### GaussianNB #######')\n",
    "print('score', gnb.score(X_test.toarray(), y_test))\n",
    "print(classification_report(y_test, y_pred_gnb))\n",
    "print('confusion matrix\\n', confusion_matrix(y_test, y_pred_gnb))\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "y_pred_lsvc = lsvc.predict(X_test.toarray())\n",
    "print('####### LinearSVC #######')\n",
    "print('score', lsvc.score(X_test.toarray(), y_test))\n",
    "print(classification_report(y_test, y_pred_lsvc))\n",
    "print('confusion matrix\\n', confusion_matrix(y_test, y_pred_lsvc))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
